{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Проект: Линейная и логистическая регрессия с нуля\n",
        "\n",
        "**Участник:** Гаськов Валерий\n",
        "\n",
        "**Описание:** В проекте реализованы:\n",
        "- Линейная регрессия с градиентным спуском (batch и mini-batch)\n",
        "- Логистическая регрессия с градиентным спуском (binary и multiclass)\n",
        "- Классификация с дополнительной моделью Random Forest\n",
        "- Метрики: accuracy, precision, recall, F1-score, confusion matrix, ROC AUC (для бинарной классификации)\n",
        "- Интерактивный интерфейс с виджетами для настройки гиперпараметров и выбора модели\n",
        "\n",
        "**Датасет:**  \n",
        "Использован публичный датасет `master.csv`  \n",
        "Источник: [Kaggle — Suicide Rates Overview 1985 to 2016](https://www.kaggle.com/datasets/russellyates88/suicide-rates-overview-1985-to-2016/discussion/570568)\n"
      ],
      "metadata": {
        "id": "a2HSgN0Gmcqv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDa0bA6nU1il"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "df = pd.read_csv(\"master.csv\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Формулы градиентов линейной регрессии:\n",
        "$\n",
        "\\hat y = wX + b\n",
        "$\n",
        "\n",
        "Функция потерь (MSE):\n",
        "$\n",
        "L=\\frac{1}{N}\\sum (y - \\hat y)^2\n",
        "$\n",
        "\n",
        "Градиенты:\n",
        "$\n",
        "frac{\\partial L}{\\partial w} = -\\frac{2}{N}\\sum X(y - \\hat y)\n",
        "$\n",
        "$\n",
        "frac{\\partial L}{\\partial b} = -\\frac{2}{N}\\sum (y - \\hat y)\n",
        "$"
      ],
      "metadata": {
        "id": "w5xR-qYXcpPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 1\n",
        "Линейная регрессия (реализация с нуля).\n",
        "Реализовать градиентный спуск (batch или mini-batch) для обучения линейной регрессии.\n",
        "Вывести и показать: функция потерь (MSE), график потерь по эпохам, влияние скорости обучения (learning rate), найденные коэффициент и интерсепт.\n",
        "На странице/в ноутбуке — scatter plot данных и линия регрессии с доверительным интервалом.\n"
      ],
      "metadata": {
        "id": "r3HFJX_WlFYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция MSE"
      ],
      "metadata": {
        "id": "E-oPHd9bXRQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)"
      ],
      "metadata": {
        "id": "djO00sJEVPcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Gradient Descent — реализация вручную"
      ],
      "metadata": {
        "id": "RMYE7g2bXW9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_linear_regression(X, y, lr=0.01, epochs=1000):\n",
        "    n = X.shape[0]\n",
        "\n",
        "\n",
        "    w = 0.0\n",
        "    b = 0.0\n",
        "\n",
        "    history = []\n",
        "\n",
        "    for _ in tqdm(range(epochs)):\n",
        "        y_pred = w * X + b\n",
        "\n",
        "        error = y_pred - y\n",
        "\n",
        "        dw = (2/n) * np.sum(error * X)\n",
        "        db = (2/n) * np.sum(error)\n",
        "\n",
        "        w -= lr * dw\n",
        "        b -= lr * db\n",
        "\n",
        "        history.append(mse(y, y_pred))\n",
        "\n",
        "    return w, b, history"
      ],
      "metadata": {
        "id": "NVPJb9mEXXpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mini-Batch Gradient Descent"
      ],
      "metadata": {
        "id": "AeesXatTXm71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_linear_regression_minibatch(X, y, lr=0.01, epochs=1000, batch_size=32):\n",
        "    n = X.shape[0]\n",
        "    w = 0.0\n",
        "    b = 0.0\n",
        "    history = []\n",
        "\n",
        "    for _ in tqdm(range(epochs)):\n",
        "        indices = np.random.permutation(n)\n",
        "        X_shuffled = X[indices]\n",
        "        y_shuffled = y[indices]\n",
        "\n",
        "        for start in range(0, n, batch_size):\n",
        "            end = start + batch_size\n",
        "            Xb = X_shuffled[start:end]\n",
        "            yb = y_shuffled[start:end]\n",
        "\n",
        "            pred = w * Xb + b\n",
        "            err = pred - yb\n",
        "\n",
        "            dw = (2/len(Xb)) * np.sum(err * Xb)\n",
        "            db = (2/len(Xb)) * np.sum(err)\n",
        "\n",
        "            w -= lr * dw\n",
        "            b -= lr * db\n",
        "\n",
        "        pred_full = w * X + b\n",
        "        history.append(mse(y, pred_full))\n",
        "\n",
        "    return w, b, history\n"
      ],
      "metadata": {
        "id": "gTWVAmyUXmPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запуск обучения + эксперименты с learning rate"
      ],
      "metadata": {
        "id": "OeSqHM2YXpOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "X = df['population'].values.reshape(-1, 1)\n",
        "y = df['suicides/100k pop'].values.reshape(-1, 1)\n",
        "\n",
        "X_mean = np.mean(X)\n",
        "X_std = np.std(X)\n",
        "Xn = (X - X_mean) / X_std\n",
        "\n",
        "print(f\"Shape of Xn: {Xn.shape}\")\n",
        "print(f\"Shape of y: {y.shape}\")"
      ],
      "metadata": {
        "id": "PF_BBkAzHEUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrs = [0.001, 0.01, 0.1]\n",
        "\n",
        "results = {}\n",
        "\n",
        "for lr in lrs:\n",
        "    w, b, h = train_linear_regression(Xn, y, lr=lr, epochs=300)\n",
        "    results[lr] = (w, b, h)\n",
        "    print(f\"LR={lr} → w={w:.4f}, b={b:.4f}, final MSE={h[-1]:.4f}\")"
      ],
      "metadata": {
        "id": "58k13JAmXr0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "График потерь для разных learning rate"
      ],
      "metadata": {
        "id": "rfQAGxGBXta9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "for lr in lrs:\n",
        "    _, _, h = results[lr]\n",
        "    plt.plot(h, label=f\"lr={lr}\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Loss vs Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-P6sog84cTMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Построение линии регрессии"
      ],
      "metadata": {
        "id": "gvhoo3XMcUIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "w, b, h = results[lr]\n",
        "\n",
        "y_pred = w * Xn + b\n",
        "\n",
        "X_sorted = np.sort(X, axis=0)\n",
        "Xn_sorted = (X_sorted - X_mean) / X_std\n",
        "y_pred_sorted = w * Xn_sorted + b\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(X, y, alpha=0.6, label=\"Data\")\n",
        "plt.plot(X_sorted, y_pred_sorted, 'r', label=\"Regression line\")"
      ],
      "metadata": {
        "id": "YatHi_TncWEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Доверительный интервал"
      ],
      "metadata": {
        "id": "cF3cVJ9YcemG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errors = y - y_pred\n",
        "sigma = errors.std()\n",
        "ci_upper = y_pred_sorted + 1.96 * sigma\n",
        "ci_lower = y_pred_sorted - 1.96 * sigma\n",
        "plt.fill_between(X_sorted.flatten(), ci_lower.flatten(), ci_upper.flatten(),\n",
        "                 color='red', alpha=0.2, label=\"95% CI\")\n",
        "\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Linear Regression with Confidence Interval\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hsSFaFqqcako"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Логистическая регрессия (реализация с нуля).\n",
        "Реализовать лог-функцию, сигмоиду и обучение градиентным спуском (можно использовать регуляризацию L2 по желанию).\n"
      ],
      "metadata": {
        "id": "dKjDSMgHlQb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель:\n",
        "$z = X w + b,\\quad \\hat{p} = \\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
        "\n",
        "Функция потерь:\n",
        "$L = -\\frac{1}{N} \\sum_{i=1}^{N} \\Big[ y_i \\log \\hat{p}_i + (1 - y_i) \\log (1 - \\hat{p}_i) \\Big]$\n",
        "\n",
        "Градиенты:\n",
        "\n",
        "$\\frac{\\partial L}{\\partial w} = \\frac{1}{N} X^\\top (\\hat{p} - y)$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial b} = \\frac{1}{N} \\sum_{i=1}^{N} (\\hat{p}_i - y_i)$\n"
      ],
      "metadata": {
        "id": "HNv5MeOyd7RF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Базовые функции"
      ],
      "metadata": {
        "id": "X6cuEUOudjGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def binary_cross_entropy(y_true, y_pred):\n",
        "    eps = 1e-8\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))"
      ],
      "metadata": {
        "id": "NhSOYiJsceSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Gradient Descent (без L2)"
      ],
      "metadata": {
        "id": "ZwH1ZKxqeXbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_logistic_regression(X, y, lr=0.01, epochs=1000, l2_lambda=0.0):\n",
        "    n_samples, n_features = X.shape\n",
        "    w = np.zeros((n_features, 1))\n",
        "    b = 0.0\n",
        "    history = []\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        z = X.dot(w) + b\n",
        "        y_pred = sigmoid(z)\n",
        "\n",
        "        dw = (1/n_samples) * X.T.dot(y_pred - y) + l2_lambda * w\n",
        "        db = (1/n_samples) * np.sum(y_pred - y)\n",
        "\n",
        "        w -= lr * dw\n",
        "        b -= lr * db\n",
        "\n",
        "        loss = binary_cross_entropy(y, y_pred)\n",
        "        history.append(loss)\n",
        "\n",
        "    return w, b, history"
      ],
      "metadata": {
        "id": "y7bEDxVieYNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрика точности"
      ],
      "metadata": {
        "id": "VAvUuUkXeepH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, w, b, threshold=0.5):\n",
        "    y_prob = sigmoid(X.dot(w) + b)\n",
        "    return (y_prob >= threshold).astype(int)"
      ],
      "metadata": {
        "id": "yg9ej9GnebcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "График потерь"
      ],
      "metadata": {
        "id": "YaR2b54DegYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "w, b, history = train_logistic_regression(X, y, lr=0.1, epochs=300)\n",
        "\n",
        "plt.plot(history)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Binary Cross-Entropy Loss\")\n",
        "plt.title(\"Logistic Regression Loss over Epochs\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MoulaoF_emXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверка точности на обучающей выборке"
      ],
      "metadata": {
        "id": "xApeKC38enUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(X, w, b)\n",
        "accuracy = np.mean(y_pred == y)\n",
        "print(f\"Accuracy on training set: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "LJgO15cUeq2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 3. Классификация (binary / multiclass)"
      ],
      "metadata": {
        "id": "iLbZcLiXesGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.unique(y)\n",
        "if len(classes) > 2:\n",
        "    print(\"Multiclass classification (one-vs-rest)\")\n",
        "else:\n",
        "    print(\"Binary classification\")"
      ],
      "metadata": {
        "id": "tJ0trrhAfMnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Логистическая регрессия (из пункта 2)"
      ],
      "metadata": {
        "id": "S6J_8r3UfYfV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d9574f1"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le_sex = LabelEncoder()\n",
        "y_binary = le_sex.fit_transform(df['sex']).reshape(-1, 1)\n",
        "\n",
        "print(f\"Unique values in y_binary: {np.unique(y_binary)}\")\n",
        "print(f\"Shape of y_binary: {y_binary.shape}\")\n",
        "\n",
        "le_age = LabelEncoder()\n",
        "y_multi = le_age.fit_transform(df['age']).reshape(-1, 1)\n",
        "age_classes = le_age.classes_\n",
        "\n",
        "print(f\"Unique values in y_multi: {np.unique(y_multi)}\")\n",
        "print(f\"Shape of y_multi: {y_multi.shape}\")\n",
        "print(f\"Age classes: {age_classes}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_bin, b_bin, history_bin = train_logistic_regression(Xn, y_binary, lr=0.1, epochs=300)\n",
        "\n",
        "y_pred_bin = predict(Xn, w_bin, b_bin)\n",
        "accuracy_bin = np.mean(y_pred_bin == y_binary)\n",
        "print(f\"Binary Logistic Regression accuracy (sex): {accuracy_bin:.4f}\")"
      ],
      "metadata": {
        "id": "pEcm5frNfaZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель и прогноз:\n",
        "\n",
        "$\\hat{p} = \\sigma(z) = \\frac{1}{1 + e^{-z}}, \\quad z = X w + b$\n",
        "\n",
        "\n",
        "Функция потерь (binary cross-entropy):\n",
        "\n",
        "$L = -\\frac{1}{N} \\sum_{i=1}^{N} \\Big[ y_i \\log \\hat{p}_i + (1 - y_i) \\log (1 - \\hat{p}_i) \\Big]$\n",
        "\n",
        "\n",
        "Градиенты по весам и смещению:\n",
        "\n",
        "$\\frac{\\partial L}{\\partial w} = \\frac{1}{N} X^\\top (\\hat{p} - y)$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial b} = \\frac{1}{N} \\sum_{i=1}^{N} (\\hat{p}_i - y_i)$"
      ],
      "metadata": {
        "id": "jydCEaYOfjZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiclass Logistic Regression (one-vs-rest)"
      ],
      "metadata": {
        "id": "Pv2MPjtgir9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = len(age_classes)\n",
        "w_multi = []\n",
        "b_multi = []\n",
        "\n",
        "for cls_idx in range(n_classes):\n",
        "    y_cls = (y_multi == cls_idx).astype(int)\n",
        "    w, b, _ = train_logistic_regression(Xn, y_cls, lr=0.1, epochs=300)\n",
        "    w_multi.append(w)\n",
        "    b_multi.append(b)\n",
        "\n",
        "pred_probs = np.column_stack([sigmoid(Xn.dot(w)+b) for w,b in zip(w_multi,b_multi)])\n",
        "y_pred_multi = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "accuracy_multi = np.mean(y_pred_multi.reshape(-1,1) == y_multi)\n",
        "print(f\"Multiclass Logistic Regression accuracy (age): {accuracy_multi:.4f}\")"
      ],
      "metadata": {
        "id": "kD6S63tSi_EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest (sklearn)"
      ],
      "metadata": {
        "id": "lSrVDkS1fwQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rf_bin = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_bin.fit(Xn, y_binary.ravel())\n",
        "y_pred_rf_bin = rf_bin.predict(Xn)\n",
        "accuracy_rf_bin = accuracy_score(y_binary, y_pred_rf_bin)\n",
        "print(f\"Random Forest accuracy (binary sex): {accuracy_rf_bin:.4f}\")\n",
        "\n",
        "rf_multi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_multi.fit(Xn, y_multi.ravel())\n",
        "y_pred_rf_multi = rf_multi.predict(Xn)\n",
        "accuracy_rf_multi = accuracy_score(y_multi, y_pred_rf_multi)\n",
        "print(f\"Random Forest accuracy (multiclass age): {accuracy_rf_multi:.4f}\")"
      ],
      "metadata": {
        "id": "LoKmx9e3fhXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравнение моделей и график"
      ],
      "metadata": {
        "id": "QjfLijsbiPkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar([\"LogReg Binary\", \"RF Binary\"], [accuracy_bin, accuracy_rf_bin], color=['skyblue','salmon'])\n",
        "plt.ylim(0,1)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Binary Classification Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "plt.bar([\"LogReg Multi\", \"RF Multi\"], [accuracy_multi, accuracy_rf_multi], color=['lightgreen','orange'])\n",
        "plt.ylim(0,1)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Multiclass Classification Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Vftn46biSXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Метрики для всех моделей"
      ],
      "metadata": {
        "id": "VYNvMNdJjdII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "def evaluate_classification(y_true, y_pred, y_prob=None, binary=False):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average='binary' if binary else 'macro')\n",
        "    rec = recall_score(y_true, y_pred, average='binary' if binary else 'macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='binary' if binary else 'macro')\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(\"Accuracy:\", round(acc,4))\n",
        "    print(\"Precision:\", round(prec,4))\n",
        "    print(\"Recall:\", round(rec,4))\n",
        "    print(\"F1-score:\", round(f1,4))\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "    if binary and y_prob is not None:\n",
        "        auc = roc_auc_score(y_true, y_prob)\n",
        "        print(\"ROC AUC:\", round(auc,4))\n",
        "        return acc, prec, rec, f1, cm, auc\n",
        "    return acc, prec, rec, f1, cm"
      ],
      "metadata": {
        "id": "HiurMGBkkZVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Применение для логистической регрессии (binary):\n"
      ],
      "metadata": {
        "id": "sWWMWArPkfx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_bin = sigmoid(Xn.dot(w_bin) + b_bin)\n",
        "evaluate_classification(y_binary, y_pred_bin, y_pred_prob_bin, binary=True)"
      ],
      "metadata": {
        "id": "5p-CgkgPkdj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для multiclass или Random Forest:"
      ],
      "metadata": {
        "id": "qtia9w8hkmZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_classification(y_multi, y_pred_multi, binary=False)\n",
        "evaluate_classification(y_multi, y_pred_rf_multi, binary=False)"
      ],
      "metadata": {
        "id": "p4Qnh18rkikQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Эксперименты с hyperparameters"
      ],
      "metadata": {
        "id": "UDoK_5Pxkq9V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e65b66fe"
      },
      "source": [
        "def train_logistic_regression_minibatch(X, y, lr=0.01, epochs=1000, batch_size=32, l2_lambda=0.0):\n",
        "    n_samples, n_features = X.shape\n",
        "    w = np.zeros((n_features, 1))\n",
        "    b = 0.0\n",
        "    history = []\n",
        "\n",
        "    for _ in tqdm(range(epochs)):\n",
        "        indices = np.random.permutation(n_samples)\n",
        "        X_shuffled = X[indices]\n",
        "        y_shuffled = y[indices]\n",
        "\n",
        "        for start in range(0, n_samples, batch_size):\n",
        "            end = start + batch_size\n",
        "            Xb = X_shuffled[start:end]\n",
        "            yb = y_shuffled[start:end]\n",
        "\n",
        "            if len(Xb) == 0:\n",
        "                continue\n",
        "\n",
        "            z = Xb.dot(w) + b\n",
        "            y_pred = sigmoid(z)\n",
        "\n",
        "            dw = (1/len(Xb)) * Xb.T.dot(y_pred - yb) + l2_lambda * w\n",
        "            db = (1/len(Xb)) * np.sum(y_pred - yb)\n",
        "\n",
        "            w -= lr * dw\n",
        "            b -= lr * db\n",
        "\n",
        "        z_full = X.dot(w) + b\n",
        "        y_pred_full = sigmoid(z_full)\n",
        "        loss = binary_cross_entropy(y, y_pred_full)\n",
        "        history.append(loss)\n",
        "\n",
        "    return w, b, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrs = [0.001, 0.01, 0.1]\n",
        "epochs_list = [100, 300, 500]\n",
        "batch_sizes = [16, 32, 64]\n",
        "\n",
        "for lr in lrs:\n",
        "    for epochs in epochs_list:\n",
        "        for batch in batch_sizes:\n",
        "            w, b, h = train_logistic_regression_minibatch(Xn, y_binary, lr=lr, epochs=epochs, batch_size=batch)\n",
        "            print(f\"LR={lr}, epochs={epochs}, batch={batch}, final loss={h[-1]:.4f}\")"
      ],
      "metadata": {
        "id": "Dg3qLuijkqjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Интерфейс / демонстрация с виджетами (Jupyter / ipywidgets)"
      ],
      "metadata": {
        "id": "D01tkg4XkveK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "lr_slider = widgets.FloatLogSlider(value=0.01, base=10, min=-3, max=0, step=0.1, description='LR')\n",
        "epochs_slider = widgets.IntSlider(value=300, min=50, max=1000, step=50, description='Epochs')\n",
        "batch_slider = widgets.IntSlider(value=32, min=8, max=128, step=8, description='Batch Size')\n",
        "model_select = widgets.Dropdown(options=['Logistic Regression', 'Random Forest'], description='Model')\n",
        "target_select = widgets.Dropdown(options=['sex (binary)', 'age (multiclass)'], description='Target')\n",
        "\n",
        "button_run = widgets.Button(description=\"Train & Evaluate\")\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def on_button_click(b):\n",
        "    with out:\n",
        "        clear_output()\n",
        "        if target_select.value == 'sex (binary)':\n",
        "            X_train, y_train = Xn, y_binary\n",
        "            binary = True\n",
        "        else:\n",
        "            X_train, y_train = Xn, y_multi\n",
        "            binary = False\n",
        "\n",
        "        if model_select.value == 'Logistic Regression':\n",
        "            w, b_val, history = train_logistic_regression_minibatch(\n",
        "                X_train, y_train, lr=lr_slider.value, epochs=epochs_slider.value, batch_size=batch_slider.value\n",
        "            )\n",
        "            y_pred = predict(X_train, w, b_val)\n",
        "            if binary:\n",
        "                y_prob = sigmoid(X_train.dot(w)+b_val)\n",
        "                evaluate_classification(y_train, y_pred, y_prob, binary=True)\n",
        "            else:\n",
        "                n_classes = len(np.unique(y_train))\n",
        "                w_all, b_all = [], []\n",
        "                for cls_idx in range(n_classes):\n",
        "                    y_cls = (y_train == cls_idx).astype(int)\n",
        "                    w_tmp, b_tmp, _ = train_logistic_regression(X_train, y_cls, lr=lr_slider.value, epochs=epochs_slider.value)\n",
        "                    w_all.append(w_tmp)\n",
        "                    b_all.append(b_tmp)\n",
        "                pred_probs = np.column_stack([sigmoid(X_train.dot(w)+b) for w,b in zip(w_all,b_all)])\n",
        "                y_pred_multi = np.argmax(pred_probs, axis=1)\n",
        "                evaluate_classification(y_train, y_pred_multi, binary=False)\n",
        "\n",
        "            plt.plot(history)\n",
        "            plt.xlabel(\"Epoch\")\n",
        "            plt.ylabel(\"Loss\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            from sklearn.ensemble import RandomForestClassifier\n",
        "            rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "            rf.fit(X_train, y_train.ravel())\n",
        "            y_pred = rf.predict(X_train)\n",
        "            evaluate_classification(y_train, y_pred, binary=binary)\n",
        "\n",
        "button_run.on_click(on_button_click)\n",
        "\n",
        "display(lr_slider, epochs_slider, batch_slider, model_select, target_select, button_run, out)"
      ],
      "metadata": {
        "id": "kjhRJ59ckxs1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}